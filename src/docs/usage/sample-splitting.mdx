---
title: Sample splitting
description: Learn how to use VoiceSmith to automatically split a dataset at sentence breaks for use in text-to-speech.
---

## What is sample splitting?

Real world datasets often contain samples which contain multiple sentences. This is problematic in three ways:

1. If some samples contain a single sentence and some samples contain multiple sentences it can confuse the model
   and make it harder to learn from the data.
2. Missmatch during training and inference: While in training the model learns to map one or more sentences to speech in
   one forward pass, during inference the model usually is only given a single sentence.
3. RAM/VRAM requirements during training are directly proportional to the longest sample in the dataset. Therefore, the default
   training configuration will ignore samples with a duration exceeding 10 seconds. If you split the long samples into smaller ones
   you can therefore increase the size of your dataset which improves the final model.

VoiceSmith can automatically split samples in your dataset as sentence breaks, this works on all [supported languages](/).

## How to split a dataset at sentence breaks

### Creating a sample splitting run

In order to sample split a dataset you have to create a new sample splitting run. Click on
"Preprocessing" in the navigation and then click on "New Sample Splitting Run". Afterwards
click on "select" on the right side of the newly created run. The process of sample splitting
is split into three steps:

### Configuration

Here you can configure your sample splitting run. Current configuration options include:

| Name                      | Description                                                                                                                                                                                                                                                                                                                                                       |
| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                      | Name used for identification purposes, is arbitrary.                                                                                                                                                                                                                                                                                                              |
| Maximum Worker Count      | Equivalent to the number of CPU cores to use during parts of preprocessing. Should be less or equal to the number of cores your CPU has. If set on "auto" this will be set to maximum(1, number of CPU cores). Also has an influence on the RAM usage during preprocessing, if your run suddenly freezes during preprocessing reducing the worker count may help. |
| On Error Ignore Sample    | Controls the behaviour of what will happen if a sample in your dataset could not be loaded for some reason. If set to "Yes" the sample will be ignored in the run and a message will be written into the log. If set to "No" a message will be written into the log and the run will be stopped.                                                                  |
| Forced Aligner Batch Size | How many samples to process at once during aligning the text with the audio files. Higher numbers mean faster alignment but larger disk space requirements together with a higher chance for things to go wrong. Recommended to be set to a very high value like 200.000.                                                                                         |
| Dataset                   | Dataset to normalize, if a dataset is greyed out is already referenced by a run. If you haven't imported a dataset yet check out [Importing a dataset](/usage/importing-a-dataset).                                                                                                                                                                               |
| Device                    | Controls whether you want to use the CPU or GPU for ressource hungry computations. It is highly advised to set this to GPU if possible. If the GPU greyed out your graphics card may not be supported by CUDA.                                                                                                                                                    |
