---
title: Sample splitting
description: Learn how to use VoiceSmith to automatically split a dataset at sentence breaks for use in text-to-speech.
---

## What is sample splitting?

Datasets outside the comfortable academic world often contain samples containing multiple sentences.
This is problematic in three ways:

1. If some samples contain a single sentence and some samples contain multiple sentences, it can confuse the model
   and make it harder to learn from the data.
2. Missmatch during training and inference: While in training, the model learns to map one or more sentences to speech in
   one forward pass, during inference the model usually is only given a single sentence.
3. RAM/VRAM requirements during training are directly proportional sample in the dataset with the highest duration.
   Therefore, the default training configuration will ignore samples with a duration exceeding 10 seconds.
   If you split the long samples into smaller ones, you can increase the size of your dataset,
   improving the final model.

VoiceSmith can automatically split samples in your dataset at sentence breaks.
This works on all [supported languages](/).

## How to split a dataset at sentence breaks

### Creating a sample splitting run

To sample split a dataset, you must to create a new sample splitting run. Click on
"Preprocessing" in the navigation and click on "New Sample Splitting Run." Afterward,
click "select" on the right side of the newly created run. The process of sample splitting
is split into three steps:

### Configuration

Here you can configure your sample splitting run. Current configuration options include:

| Name                      | Description                                                                                                                                                                                                                                                                                                                                                             |
| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Name                      | Name used for identification purposes. Arbitrary.                                                                                                                                                                                                                                                                                                                       |
| Maximum Worker Count      | Equivalent to the number of CPU cores to use during parts of preprocessing. It should be less or equal to the number of cores your CPU has. If set to "auto," this will be set to maximum(1, number of CPU cores). Also has an influence on the RAM usage during preprocessing - if your run suddenly freezes during preprocessing, reducing the worker count may help. |
| On Error Ignore Sample    | Controls the behaviour of what will happen if a sample in your dataset could not be loaded for some reason. If set to "Yes," the sample will be ignored and a message will be written into the log. If set to "No" a message will be written into the log and the run will be stopped.                                                                                  |
| Forced Aligner Batch Size | How many samples to process at once while aligning the text with the audio files. Higher numbers mean faster alignment but more extensive disk space requirements and a higher chance for things to go wrong. Recommended to be set to a very high value like 200.000.                                                                                                  |
| Dataset                   | Dataset to normalize. If a dataset is greyed out, it is already referenced by a run. If you haven't imported a dataset, check out [Importing a dataset](/usage/importing-a-dataset).                                                                                                                                                                                    |
| Device                    | Controls whether you want to use the CPU or GPU for ressource hungry computations. It is highly advised to set this to GPU if possible. If the GPU greyed out, your graphics card mght not be supported by CUDA.                                                                                                                                                        |

### Preprocessing

After you have configured the sample splitting run, it's waiting time. VoiceSmith will calculate the locations on
where to split your text and audio files using four steps:

1. Copy Files:
   Samples will be copied into a temporary folder for further processing.
2. Generate Vocabulary:
   A multilingual grapheme to phoneme model (G2P) will be used to generate a table that
   maps every word in your datasets to its phonemes.
3. Generate Alignments:
   With the help of [Montreal Forced Aligner](https://montreal-forced-aligner.readthedocs.io/en/latest/)
   and the generated vocabulary, timestamps are created corresponding to the beginning and end of each
   phoneme in the audio files.
4. Creating Splits:
   A sentence tokenizer is used to split the texts into sentences. Finally, the timestamps generated in
   step three will be used to separate the audios according to the sentence breaks.

Depending on the dataset size, this can take minutes to hours.

### Choose Samples

A table is shown of all samples that will be normalized. The table has the following columns:

| Column     | Description                                                  |
| ---------- | ------------------------------------------------------------ |
| Text       | Text before splitting the sample.                            |
| Speaker    | Name of the speaker the sample belongs to.                   |
| Split Into | A list containing the samples the sample will be split into. |

It is advised to at least skim through the table as sample splitting is not perfect. If there are samples
that you don't want to be split, you can select them using the checkboxes on the left and then click on "Do not split selected."
Those samples will stay in the dataset but will not be split.

If you are happy with the list of splits to apply, you can click on "Next."

### Creating Splits

VoiceSmith will now swap the samples in your dataset with the splits in the previous table. After this is finished, you can
remove the sample splitting run.
